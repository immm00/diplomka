{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72f4c581-cfb9-4c2a-bf39-b1bf5d9c052f",
   "metadata": {},
   "source": [
    "# Sentiment analysis on synthetic dataset - classic ML approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8734f609-fd51-4b0e-8f7d-7bdb3a7804db",
   "metadata": {},
   "source": [
    "Applying simple SVM and Max Entropy (Logistic Regression) on the synthetic dataset. Using 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68f06203-d11e-4fc0-b169-6f8fb11a57d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbb403d-7763-4e88-822f-3ce0c115bd84",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "348b4a78-a94b-4314-a989-41e7f665a98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads from txt files that seperately habe positive, negative and neutral texts\n",
    "def load_from_separate_txts(pos_file, neg_file, neu_file, encoding='utf-8'):\n",
    "    with open(pos_file, 'r', encoding=encoding) as file:\n",
    "        pos_texts = file.readlines()\n",
    "        \n",
    "    with open(neg_file, 'r', encoding=encoding) as file:\n",
    "        neg_texts = file.readlines()\n",
    "        \n",
    "    with open(neu_file, 'r', encoding=encoding) as file:\n",
    "        neu_texts = file.readlines()\n",
    "\n",
    "    texts=[text.strip() for text in pos_texts]+[text.strip() for text in neg_texts]+[text.strip() for text in neu_texts]\n",
    "    labels=['p']*len(pos_texts)+['n']*len(neg_texts)+['0']*len(neu_texts)\n",
    "\n",
    "    data = {\n",
    "        'texts': texts,\n",
    "        'labels': labels\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    print('data loaded')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c00c96f-31b6-4eb1-b5cc-8dc199c9f2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "data = load_from_separate_txts('datasets/synthetic_dataset/positive.txt', 'datasets/synthetic_dataset/negative.txt', 'datasets/synthetic_dataset/neutral.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce2b0a5c-dee5-4870-b53e-0920428ecfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  texts labels\n",
      "0     Vláda schválila balíček opatření, které povzbu...      p\n",
      "1     Podle posledních dat se očekává, že export zem...      p\n",
      "2     Automobilový průmysl očekává růst prodejů v ná...      p\n",
      "3     Růst oblíbenosti místních restaurací podporuje...      p\n",
      "4     VÝSTAVBA NOVÝCH PODNIKATELSKÝCH ZÓN NAVÝŠÍ HOS...      p\n",
      "...                                                 ...    ...\n",
      "7495  Vláda oznámila plán restrukturalizace veřejnéh...      0\n",
      "7496  Moderní technologie propojily lidstvo do globá...      0\n",
      "7497  Všechny členské státy se zúčastní nadcházející...      0\n",
      "7498  V České republice je koncem roku 2021 registro...      0\n",
      "7499  Podniky využívají různé strategie k maximaliza...      0\n",
      "\n",
      "[7500 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39e0f25-9307-4b7e-bf67-f18c78430843",
   "metadata": {},
   "source": [
    "### Methods for getting and summarizing the results (report for each fold and then average for all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93ae0657-a6fd-4741-b057-f8f44e12b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_report(label_col, pred_col, output_dict=False):\n",
    "    report = classification_report(label_col, pred_col, output_dict=output_dict)\n",
    "    return report\n",
    "\n",
    "def avg_reports(*args):\n",
    "    mean_dict = dict()\n",
    "    for label in reports[0].keys():\n",
    "        dictionary = dict()\n",
    "\n",
    "        if label in 'accuracy':\n",
    "            mean_dict[label] = sum(d[label] for d in reports) / len(reports)\n",
    "            continue\n",
    "\n",
    "        for key in reports[0][label].keys():\n",
    "            dictionary[key] = sum(d[label][key] for d in reports) / len(reports)\n",
    "        mean_dict[label] = dictionary\n",
    "\n",
    "    return mean_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083d1b5d-5e28-4074-a260-f1ea53b2824e",
   "metadata": {},
   "source": [
    "### Using SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d40b08c2-a43f-49d2-bc25-5bec9f0aebbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.9558303369550455, 'recall': 0.9514017661082143, 'f1-score': 0.9534245051988417, 'support': 251.1}, 'n': {'precision': 0.9557658094737264, 'recall': 0.9496268557895527, 'f1-score': 0.9526157082430974, 'support': 251.5}, 'p': {'precision': 0.9410615658310417, 'recall': 0.95042734459317, 'f1-score': 0.9455634883124986, 'support': 247.4}, 'accuracy': 0.9506666666666665, 'macro avg': {'precision': 0.9508859040866044, 'recall': 0.9504853221636456, 'f1-score': 0.9505345672514792, 'support': 750.0}, 'weighted avg': {'precision': 0.9509390087828805, 'recall': 0.9506666666666665, 'f1-score': 0.9506524270078234, 'support': 750.0}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "reports = []\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    train_df = data.iloc[train_index]\n",
    "    test_df = data.iloc[test_index]\n",
    "    \n",
    "    X_train = train_df.iloc[:, 0]\n",
    "    y_train = train_df.iloc[:, 1]\n",
    "    X_test = test_df.iloc[:, 0]\n",
    "    y_test = test_df.iloc[:, 1]\n",
    "    \n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    \n",
    "    model = SVC(kernel='linear')\n",
    "    model.fit(X_train_vec, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test_vec)\n",
    "\n",
    "    report = get_report(y_pred, y_test, output_dict=True)\n",
    "    reports.append(report)\n",
    "\n",
    "avg_report = avg_reports(reports)\n",
    "print(avg_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259a035a-1df8-4674-86d3-2fcfb64ac052",
   "metadata": {},
   "source": [
    "### Using Max Entropy (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bfea105-e060-4682-b110-35944a3370bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.9605487317782136, 'recall': 0.9320340840188935, 'f1-score': 0.9458520115642578, 'support': 257.6}, 'n': {'precision': 0.941254518408547, 'recall': 0.9458076044594333, 'f1-score': 0.943379649893205, 'support': 248.6}, 'p': {'precision': 0.926399300189464, 'recall': 0.9494465467396276, 'f1-score': 0.9376857861762794, 'support': 243.8}, 'accuracy': 0.9425333333333334, 'macro avg': {'precision': 0.9427341834587416, 'recall': 0.9424294117393182, 'f1-score': 0.9423058158779142, 'support': 750.0}, 'weighted avg': {'precision': 0.9430740643764647, 'recall': 0.9425333333333334, 'f1-score': 0.9425236294201721, 'support': 750.0}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "reports = []\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    train_df = data.iloc[train_index]\n",
    "    test_df = data.iloc[test_index]\n",
    "    \n",
    "    X_train = train_df.iloc[:, 0]\n",
    "    y_train = train_df.iloc[:, 1]\n",
    "    X_test = test_df.iloc[:, 0]\n",
    "    y_test = test_df.iloc[:, 1]\n",
    "    \n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    \n",
    "    model = LogisticRegression(max_iter=1000) \n",
    "    model.fit(X_train_vec, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test_vec)\n",
    "\n",
    "    report = get_report(y_pred, y_test, output_dict=True)\n",
    "    reports.append(report)\n",
    "\n",
    "avg_report = avg_reports(reports)\n",
    "print(avg_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dfae0a4-672b-4cb8-9c84-850d8db7b277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been split into 10 folds and saved in 'output_folds_synth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Python311\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in callback BaseSelectorEventLoop._read_from_self()\n",
      "handle: <Handle BaseSelectorEventLoop._read_from_self()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Python311\\Lib\\asyncio\\selector_events.py\", line 119, in _read_from_self\n",
      "    data = self._ssock.recv(4096)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "df = data\n",
    "\n",
    "# Define label mapping to folder names\n",
    "label_mapping = {'p': 'positive', 'n': 'negative', '0': 'neutral'}\n",
    "\n",
    "# Create KFold splitter\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# Base output directory\n",
    "output_dir = \"output_folds_synth\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create folds\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(df), 1):\n",
    "    fold_dir = os.path.join(output_dir, f\"fold_{fold}\")\n",
    "    for split, indices in [(\"train\", train_idx), (\"test\", test_idx)]:\n",
    "        for label, folder in label_mapping.items():\n",
    "            split_dir = os.path.join(fold_dir, split, folder)\n",
    "            os.makedirs(split_dir, exist_ok=True)\n",
    "        \n",
    "        # Save texts to corresponding folders\n",
    "        for idx in indices:\n",
    "            text = df.iloc[idx][\"texts\"]\n",
    "            label = df.iloc[idx][\"labels\"]\n",
    "            label_folder = os.path.join(fold_dir, split, label_mapping[label])\n",
    "            # Write text to a .txt file\n",
    "            text_file_path = os.path.join(label_folder, f\"text_{idx}.txt\")\n",
    "            with open(text_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(text)\n",
    "\n",
    "print(f\"Data has been split into 10 folds and saved in '{output_dir}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
